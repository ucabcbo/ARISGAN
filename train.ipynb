{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STBX not loaded: No module named 'snappy'\n",
      "init loaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if init.ENVIRONMENT == 'blaze':\n",
    "    import subprocess\n",
    "\n",
    "    command = 'source /usr/local/cuda/CUDA_VISIBILITY.csh'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = stdout.decode()[-2]\n",
    "    # os.environ['CUDA_HOME'] = '/opt/cuda/cuda-10.0'\n",
    "    print(stdout.decode())\n",
    "\n",
    "    command = 'source /server/opt/cuda/enable_cuda_11.0'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    command = 'echo $CUDA_VISIBLE_DEVICES'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    print(command)\n",
    "    print(stdout.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 12:11:20.145988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 12:11:20.220753: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "from dataset.reader import Reader\n",
    "import sis_toolbox as tbx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.setup_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 12:11:33.132697: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Dynamically import all classes in the directory\n",
    "directory = 'models'\n",
    "modules = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.py'):\n",
    "        module_name = filename[:-3]\n",
    "        modules.append(importlib.import_module(\".\" + module_name, package=directory))\n",
    "\n",
    "model = None\n",
    "for module in modules:\n",
    "    if module.__name__[-len(init.MODEL_NAME):] == init.MODEL_NAME:\n",
    "        model = module.GAN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = model.generator\n",
    "discriminator = model.discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_tf_version = '2.8.0'\n",
    "tf_gtet_280 = True\n",
    "for reqPart, part in zip(map(int, req_tf_version.split(\".\")), map(int, tf.__version__.split(\".\"))):\n",
    "    if reqPart > part:\n",
    "        tf_gtet_280 = False\n",
    "        break\n",
    "    if reqPart < part:\n",
    "        break\n",
    "\n",
    "if tf_gtet_280:\n",
    "    tf.keras.utils.plot_model(generator, show_shapes=True, expand_nested=True, show_layer_activations=True, to_file=os.path.join(init.OUTPUT_MODEL, 'generator.png'))\n",
    "    tf.keras.utils.plot_model(discriminator, show_shapes=True, expand_nested=True, show_layer_activations=True, to_file=os.path.join(init.OUTPUT_MODEL, 'discriminator.png'))\n",
    "else:\n",
    "    tf.keras.utils.plot_model(generator, show_shapes=True, expand_nested=True, to_file=os.path.join(init.OUTPUT_MODEL, 'generator.png'))\n",
    "    tf.keras.utils.plot_model(discriminator, show_shapes=True, expand_nested=True, to_file=os.path.join(init.OUTPUT_MODEL, 'discriminator.png'))\n",
    "None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datamodel.Reader called by train.py\n",
      "selected random sample train: 25000\n",
      "selected random sample val: 5000\n"
     ]
    }
   ],
   "source": [
    "dataset_reader = Reader(init.BATCH_SIZE, init.SHUFFLE, 'train.ipynb', init.DATA_SAMPLE)\n",
    "train_dataset = dataset_reader.train_dataset\n",
    "test_dataset = dataset_reader.test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, test_ds, steps):\n",
    "    # example_target, example_input = next(iter(test_ds.take(1)))\n",
    "    start = time.time()\n",
    "    example_targets = []\n",
    "    example_inputs = []\n",
    "    for example_target, example_input in test_dataset.take(5):\n",
    "        example_targets.append(example_target[0])\n",
    "        example_inputs.append(example_input[0])\n",
    "    example_inputs = tf.stack(example_inputs, axis=0)\n",
    "    example_targets = tf.stack(example_targets, axis=0)\n",
    "\n",
    "    for step, (target, input_image) in train_ds.repeat().take(steps).enumerate():\n",
    "        if step % init.SAMPLE_FREQ == 0:\n",
    "            # display.clear_output(wait=True)\n",
    "            \n",
    "            if step != 0:\n",
    "                print(f'Time taken for {init.SAMPLE_FREQ} steps: {time.time()-start:.2f} sec\\n')\n",
    "                start = time.time()\n",
    "            \n",
    "            tbx.generate_images(generator, example_inputs, example_targets, showimg=False, PATH_IMGS=init.OUTPUT_SAMPLES, savemodel=init.MODEL_NAME, iteration=step)\n",
    "            # for example_target, example_input in test_dataset.take(1):\n",
    "            #     helper.generate_images(generator, example_input, example_target, showimg=False, PATH_IMGS=path_imgs, savemodel=model.name, starttimestamp=STARTTIME, iteration=step)\n",
    "\n",
    "            print(f\"Step: {step}\")\n",
    "\n",
    "        model.train_step(input_image, target, step)\n",
    "\n",
    "        # Training step\n",
    "        if (step + 1) % 10 == 0:\n",
    "            print('.', end='', flush=True)\n",
    "\n",
    "        # Save (checkpoint) the model every 5k steps\n",
    "        if (step + 1) % init.CKPT_FREQ == 0:\n",
    "            print(f'Step + 1 = {step + 1} - saving checkpoint')\n",
    "            model.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 12:12:41.947690: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2023-07-13 12:12:52.030028: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 81 of 2500\n",
      "2023-07-13 12:13:02.038507: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 166 of 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 12:13:12.020258: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 258 of 2500\n"
     ]
    }
   ],
   "source": [
    "fit(train_dataset, test_dataset, steps=init.STEPS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations / not for train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sample_dataset = tf.data.TFRecordDataset(os.path.join(init.VAL_DIR, random.choice(os.listdir(init.VAL_DIR))))\n",
    "for element in sample_dataset:\n",
    "    tbx.plot_tensor_sbs(element, init.TILESIZE)\n",
    "    s2_tensor, s3_tensor = tbx.parse_tfrecord(element, init.TILESIZE)\n",
    "    s2_tensor, s3_tensor = dataset_reader.resize(s2_tensor, s3_tensor, init.IMG_HEIGHT, init.IMG_WIDTH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sis_toolbox import RGBProfile as rgb\n",
    "\n",
    "gen_output = generator(s3_tensor[tf.newaxis, ...], training=False)\n",
    "tbx.plot_tensor(gen_output[0], rgb.S2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disc_out = discriminator([s3_tensor[tf.newaxis, ...], gen_output], training=False)\n",
    "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_targets = []\n",
    "example_inputs = []\n",
    "for example_target, example_input in test_dataset.take(5):\n",
    "    example_targets.append(example_target[0])\n",
    "    example_inputs.append(example_input[0])\n",
    "\n",
    "tbx.generate_images(generator, tf.stack(example_inputs, axis=0), tf.stack(example_targets, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir {PATH_LOGS}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
