{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('env.txt') as f:\n",
    "    ENVIRONMENT = f.readlines()[0][:-1]\n",
    "print(f'running on environment: \"{ENVIRONMENT}\"')\n",
    "assert ENVIRONMENT in ['blaze',\n",
    "                       'colab',\n",
    "                       'local',\n",
    "                       'cpom']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENVIRONMENT == 'blaze':\n",
    "\n",
    "    import subprocess\n",
    "    import os\n",
    "\n",
    "    command = 'source /usr/local/cuda/CUDA_VISIBILITY.csh'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = stdout.decode()[-2]\n",
    "    # os.environ['CUDA_HOME'] = '/opt/cuda/cuda-10.0'\n",
    "\n",
    "    print(stdout.decode())\n",
    "\n",
    "    command = 'source /server/opt/cuda/enable_cuda_11.0'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    !echo $CUDA_VISIBLE_DEVICES\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENVIRONMENT == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/MyDrive/sis2/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Uo1QiX8kP6N7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sis_helper as helper\n",
    "from sis_helper import RGBProfile as rgb\n",
    "\n",
    "from models import pix2pix, psgan\n",
    "from dataset.reader import Reader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if True]\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name != '':\n",
    "        print('TensorFlow is using GPU:', device_name)\n",
    "    else:\n",
    "        print('TensorFlow is not using GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vztjnCBAP6N9"
   },
   "outputs": [],
   "source": [
    "TILESIZE = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "# TILESIZE = 960\n",
    "# IMG_WIDTH = 1024\n",
    "# IMG_HEIGHT = 1024\n",
    "\n",
    "INPUT_CHANNELS = 21\n",
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "if ENVIRONMENT == 'blaze':\n",
    "    PATH_PREFIX = '/cs/student/msc/aisd/2022/cboehm/projects/li1_data/'\n",
    "elif ENVIRONMENT == 'colab':\n",
    "    PATH_PREFIX = f'/content/drive/MyDrive/sis2/data/'\n",
    "elif ENVIRONMENT == 'local':\n",
    "    PATH_PREFIX = f'/Users/christianboehm/projects/sis2/data/'\n",
    "elif ENVIRONMENT == 'cpom':\n",
    "    PATH_PREFIX = f'/home/cb/sis2/data/'\n",
    "else:\n",
    "    PATH_PREFIX = f'~/projects/sis2/data'\n",
    "\n",
    "PATH_TRAIN = os.path.join(PATH_PREFIX, f'tfrecords{TILESIZE}/')\n",
    "PATH_VAL = os.path.join(PATH_PREFIX, f'tfrecords{TILESIZE}/')\n",
    "PATH_LOGS = os.path.join(PATH_PREFIX, 'logs/')\n",
    "PATH_CKPT = os.path.join(PATH_PREFIX, 'checkpoints/')\n",
    "PATH_IMGS = os.path.join(PATH_PREFIX, 'images/')\n",
    "\n",
    "# The training set consist of n images\n",
    "BUFFER_SIZE = number_of_files = len(glob.glob(os.path.join(PATH_TRAIN, '*')))\n",
    "# BUFFER_SIZE = 1077\n",
    "# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n",
    "BATCH_SIZE = 50\n",
    "LAMBDA = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pix2pix.Model(IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNELS, OUTPUT_CHANNELS, LAMBDA, PATH_LOGS, PATH_CKPT)\n",
    "model = psgan.Model(IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNELS, OUTPUT_CHANNELS, LAMBDA, PATH_LOGS, PATH_CKPT)\n",
    "\n",
    "dataset_reader = Reader(TILESIZE, IMG_HEIGHT, IMG_WIDTH, PATH_TRAIN, PATH_VAL, BUFFER_SIZE, BATCH_SIZE)\n",
    "train_dataset = dataset_reader.train_dataset\n",
    "test_dataset = dataset_reader.test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 6390,
     "status": "ok",
     "timestamp": 1670672222035,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "8QTj7LI5P6N-",
    "outputId": "56e1b195-423a-45e0-bc9e-bcf29d8a0970"
   },
   "outputs": [],
   "source": [
    "sample_dataset = tf.data.TFRecordDataset(os.path.join(PATH_VAL, random.choice(os.listdir(PATH_VAL))))\n",
    "for element in sample_dataset:\n",
    "    helper.plot_tensor_sbs(element, TILESIZE)\n",
    "    s2_tensor, s3_tensor = helper.parse_tfrecord(element, TILESIZE)\n",
    "    s2_tensor, s3_tensor = dataset_reader.resize(s2_tensor, s3_tensor, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "    # helper.plot_tensor(s2_tensor, rgb.S2)\n",
    "    # helper.plot_tensor(s3_tensor, rgb.S3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5047,
     "status": "ok",
     "timestamp": 1670672230961,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "OHsWEZWIP6OF",
    "outputId": "3a35e7bf-cd2d-4273-f476-f4ee14b171c8"
   },
   "outputs": [],
   "source": [
    "# # down_model = downsample(64, 4)\n",
    "# down_result = downsample(64, 4)(tf.expand_dims(s3_tensor, 0))\n",
    "# down_result = downsample(128, 4)(down_result)\n",
    "# print (down_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1670672232316,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "oDnBg2VcP6OF",
    "outputId": "f3d4b7ab-7377-43d2-9c25-edcf6a3e4ca2"
   },
   "outputs": [],
   "source": [
    "# up_model = upsample(21, 4)\n",
    "# up_result = up_model(down_result)\n",
    "# print (up_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1557,
     "status": "ok",
     "timestamp": 1670672233870,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "Oxz73_txP6OG",
    "outputId": "2cf1ec83-a9bf-425a-a6d2-3e1f754155c7"
   },
   "outputs": [],
   "source": [
    "generator = model.generator\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1670672235681,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "ySSo_3vhP6OG",
    "outputId": "386da2b1-a42c-4f87-8bf3-36976d8a831b"
   },
   "outputs": [],
   "source": [
    "gen_output = generator(s3_tensor[tf.newaxis, ...], training=False)\n",
    "helper.plot_tensor(gen_output[0], rgb.S2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1670672235692,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "hEVz0spiP6OI",
    "outputId": "cbac2db9-1cd4-42de-e1a9-6d454946518d"
   },
   "outputs": [],
   "source": [
    "discriminator = model.discriminator\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 2805,
     "status": "ok",
     "timestamp": 1670672238464,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "bjqzJMdxP6OI",
    "outputId": "f9541ff8-116e-4c37-ade8-e368bbe22da1"
   },
   "outputs": [],
   "source": [
    "disc_out = discriminator([s3_tensor[tf.newaxis, ...], gen_output], training=False)\n",
    "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1670672239039,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "rJL8zNWZP6OJ",
    "outputId": "fae0a91f-7724-48b6-8c57-d798c2874be5"
   },
   "outputs": [],
   "source": [
    "for example_target, example_input in test_dataset.take(1):\n",
    "    helper.generate_images(generator, example_input, example_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YMn5rbtP6OK"
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, test_ds, steps):\n",
    "    # example_target, example_input = next(iter(test_ds.take(1)))\n",
    "    starttimestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    start = time.time()\n",
    "    \n",
    "    for step, (target, input_image) in train_ds.repeat().take(steps).enumerate():\n",
    "        if (step) % 1000 == 0:\n",
    "            # display.clear_output(wait=True)\n",
    "            \n",
    "            if step != 0:\n",
    "                print(f'Time taken for 1000 steps: {time.time()-start:.2f} sec\\n')\n",
    "                start = time.time()\n",
    "\n",
    "            for example_target, example_input in test_dataset.take(1):\n",
    "                helper.generate_images(generator, example_input, example_target, showimg=True)\n",
    "\n",
    "            print(f\"Step: {step // 1000}k\")\n",
    "\n",
    "        model.train_step(input_image, target, step)\n",
    "\n",
    "        # Training step\n",
    "        if (step + 1) % 10 == 0:\n",
    "            print('.', end='', flush=True)\n",
    "\n",
    "        # Save (checkpoint) the model every 5k steps\n",
    "        if (step + 1) % 5000 == 0:\n",
    "            model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1twB_FRZg7oNNNESxKYSeYyYDLGTz3KLP"
    },
    "executionInfo": {
     "elapsed": 4185041,
     "status": "ok",
     "timestamp": 1670676424075,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "8mZlF3SGP6OK",
    "outputId": "374ee715-c4f8-42da-f776-68b67091704e"
   },
   "outputs": [],
   "source": [
    "fit(train_dataset, test_dataset, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132325,
     "status": "ok",
     "timestamp": 1670676989237,
     "user": {
      "displayName": "Christian Boehm",
      "userId": "07033981461789359232"
     },
     "user_tz": 0
    },
    "id": "e_CM8_KKCSvp",
    "outputId": "23bd6eed-dec5-431d-95c8-4e320a56aedb"
   },
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir {PATH_LOGS}\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
