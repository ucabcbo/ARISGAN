{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if init.ENVIRONMENT == 'blaze':\n",
    "    import subprocess\n",
    "\n",
    "    command = 'source /usr/local/cuda/CUDA_VISIBILITY.csh'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = stdout.decode()[-2]\n",
    "    # os.environ['CUDA_HOME'] = '/opt/cuda/cuda-10.0'\n",
    "    print(stdout.decode())\n",
    "\n",
    "    command = 'source /server/opt/cuda/enable_cuda_11.0'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    command = 'echo $CUDA_VISIBLE_DEVICES'\n",
    "    process = subprocess.Popen(command, shell=True, executable=\"/bin/csh\", stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    print(command)\n",
    "    print(stdout.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "from dataset.reader import Reader\n",
    "import sis_toolbox as tbx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'psgan'\n",
    "BATCH_SIZE = 1\n",
    "SUFFIX = 'test'\n",
    "SHUFFLE = 'n'\n",
    "PROGRESS_FREQ = 1000\n",
    "SAVE_FREQ = 5000\n",
    "\n",
    "SUBFOLDER = f'{init.TIMESTAMP}_{MODEL_NAME}_{BATCH_SIZE}x{init.TILESIZE}'\n",
    "if SUFFIX is not None:\n",
    "    SUBFOLDER += f'_{SUFFIX}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_logs = os.path.join(init.OUTPUT_ROOT, f'{SUBFOLDER}/logs/')\n",
    "path_ckpt = os.path.join(init.OUTPUT_ROOT, f'{SUBFOLDER}/ckpt/')\n",
    "path_imgs = os.path.join(init.OUTPUT_ROOT, f'{SUBFOLDER}/samples/')\n",
    "path_model = os.path.join(init.OUTPUT_ROOT, f'{SUBFOLDER}/model/')\n",
    "os.makedirs(path_logs, exist_ok=True)\n",
    "os.makedirs(path_ckpt, exist_ok=True)\n",
    "os.makedirs(path_imgs, exist_ok=True)\n",
    "os.makedirs(path_model, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically import all classes in the directory\n",
    "directory = 'model'\n",
    "modules = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.py'):\n",
    "        module_name = filename[:-3]\n",
    "        modules.append(importlib.import_module(\".\" + module_name, package=directory))\n",
    "\n",
    "model = None\n",
    "for module in modules:\n",
    "    if module.__name__[-len(MODEL_NAME):] == MODEL_NAME:\n",
    "        model = module.GAN(path_logs, path_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = model.generator\n",
    "discriminator = model.discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_tf_version = '2.8.0'\n",
    "tf_gtet_280 = True\n",
    "for reqPart, part in zip(map(int, req_tf_version.split(\".\")), map(int, tf.__version__.split(\".\"))):\n",
    "    if reqPart > part:\n",
    "        tf_gtet_280 = False\n",
    "        break\n",
    "    if reqPart < part:\n",
    "        break\n",
    "\n",
    "if tf_gtet_280:\n",
    "    tf.keras.utils.plot_model(generator, show_shapes=True, expand_nested=True, show_layer_activations=True, to_file=os.path.join(path_model, 'generator.png'))\n",
    "    tf.keras.utils.plot_model(discriminator, show_shapes=True, expand_nested=True, show_layer_activations=True, to_file=os.path.join(path_model, 'discriminator.png'))\n",
    "else:\n",
    "    tf.keras.utils.plot_model(generator, show_shapes=True, expand_nested=True, to_file=os.path.join(path_model, 'generator.png'))\n",
    "    tf.keras.utils.plot_model(discriminator, show_shapes=True, expand_nested=True, to_file=os.path.join(path_model, 'discriminator.png'))\n",
    "None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = False if SHUFFLE == 'n' else True\n",
    "dataset_reader = Reader(BATCH_SIZE, shuffle, 'train.py', (25000, 5000))\n",
    "train_dataset = dataset_reader.train_dataset\n",
    "test_dataset = dataset_reader.test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, test_ds, steps):\n",
    "    # example_target, example_input = next(iter(test_ds.take(1)))\n",
    "    start = time.time()\n",
    "    example_targets = []\n",
    "    example_inputs = []\n",
    "    for example_target, example_input in test_dataset.take(5):\n",
    "        example_targets.append(example_target[0])\n",
    "        example_inputs.append(example_input[0])\n",
    "    example_inputs = tf.stack(example_inputs, axis=0)\n",
    "    example_targets = tf.stack(example_targets, axis=0)\n",
    "\n",
    "    for step, (target, input_image) in train_ds.repeat().take(steps).enumerate():\n",
    "        if step % PROGRESS_FREQ == 0:\n",
    "            # display.clear_output(wait=True)\n",
    "            \n",
    "            if step != 0:\n",
    "                print(f'Time taken for {PROGRESS_FREQ} steps: {time.time()-start:.2f} sec\\n')\n",
    "                start = time.time()\n",
    "            \n",
    "            tbx.generate_images(generator, example_inputs, example_targets, showimg=False, PATH_IMGS=path_imgs, savemodel=MODEL_NAME, starttimestamp=init.TIMESTAMP, iteration=step)\n",
    "            # for example_target, example_input in test_dataset.take(1):\n",
    "            #     helper.generate_images(generator, example_input, example_target, showimg=False, PATH_IMGS=path_imgs, savemodel=model.name, starttimestamp=STARTTIME, iteration=step)\n",
    "\n",
    "            print(f\"Step: {step}\")\n",
    "\n",
    "        model.train_step(input_image, target, step)\n",
    "\n",
    "        # Training step\n",
    "        if (step + 1) % 10 == 0:\n",
    "            print('.', end='', flush=True)\n",
    "\n",
    "        # Save (checkpoint) the model every 5k steps\n",
    "        if (step + 1) % SAVE_FREQ == 0:\n",
    "            print(f'Step + 1 = {step + 1} - saving checkpoint')\n",
    "            model.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(train_dataset, test_dataset, steps=40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sample_dataset = tf.data.TFRecordDataset(os.path.join(init.VAL_DIR, random.choice(os.listdir(init.VAL_DIR))))\n",
    "for element in sample_dataset:\n",
    "    tbx.plot_tensor_sbs(element, init.TILESIZE)\n",
    "    s2_tensor, s3_tensor = tbx.parse_tfrecord(element, init.TILESIZE)\n",
    "    s2_tensor, s3_tensor = dataset_reader.resize(s2_tensor, s3_tensor, init.IMG_HEIGHT, init.IMG_WIDTH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sis_toolbox import RGBProfile as rgb\n",
    "\n",
    "gen_output = generator(s3_tensor[tf.newaxis, ...], training=False)\n",
    "tbx.plot_tensor(gen_output[0], rgb.S2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disc_out = discriminator([s3_tensor[tf.newaxis, ...], gen_output], training=False)\n",
    "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_targets = []\n",
    "example_inputs = []\n",
    "for example_target, example_input in test_dataset.take(5):\n",
    "    example_targets.append(example_target[0])\n",
    "    example_inputs.append(example_input[0])\n",
    "\n",
    "tbx.generate_images(generator, tf.stack(example_inputs, axis=0), tf.stack(example_targets, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir {PATH_LOGS}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
